\documentclass[12pt]{article}
\renewcommand{\baselinestretch}{1.5}
\usepackage[utf8]{inputenc}

\usepackage{hyperref}
\hypersetup{linktoc=all}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{algorithm2e}
\usepackage{graphicx}
\usepackage{float}

\begin{document}

\title{Parallel Processing Lab 4: \\Vector Dot Product}
\author{Sarah Peachey \& Nathan Schomer}
\maketitle


\textbf{\textit{Abstract:}} A vector dot product is the element wise
multiplication and then summation of two vectors with n elements. The
summation of all the elements is a form of reduction. The best form of
reduction is one that tries reduce branch divergence by not dividing warps
until only one warp is left.  
\newpage

\vspace{-1.5cm}
\section{Design}
\vspace{-0.25cm}


\qquad For a given input value, n elements are created. If n is greater than
the possible number of threads, then a stride is needed to bring all the
elements into shared memory. Each thread initializes a spot in the
$C\_shared$
vector to zero then brings in the A and B value multiplies them and
accumulates them the $C\_shared$ memory vector. Reduction is then performed on
the $C\_shared$ vector by splitting the vector in half and using the first
half of the threads to add the second half of the data to the first half of
the data. The first half is then halved over and over again. Branch
divergence does not occur until the size of the reduction is less than one
warp. Then the final answer is stored in the zeroeth element of the
$C\_shared$
vector, that is moved to global memory and copied back to the CPU. 

\vspace{1cm}
\begin{algorithm}[H]
	\KwData{Ad, Bd, Cd}
 	\KwResult{kernel to calculate the vector dot product}
 	calculate number of threads (k)\; 
	calculate the tid\; 
	create shared C vector\; 
	calculate number of strides\; 
	initialization shared memory\;
	\For{i = number of strides}{
		C[tid]+=Ad[tid+(k*i)]*Bd[tid+(k*i)]\;
	}
	now the element wise multiplication is in shared memory\;
	perform reduction\;
	\For{stride=k; stride>0; stride/=2}{
		if(tid<stride)
			C[tide]+=C[tid+shared]\; 
		synch\;
	}
	Cd=C[0]\;
\end{algorithm}

\pagebreak
\vspace{-0.6cm}
\section{Discussion of speed up}
\vspace{-0.4cm}

\qquad Speed-up was calculated for the vector dot roduct GPU and CPU code
and the speed up was calculated with, Equation 1. 
As seen by the speed-up ratios in Table 1, when 4096 threads are used there
is definitive speed up but the epsilon values were in the range of 10-50.
Whereas, where the code was ran with 1024 threads there was actually a slow
down do to the overhead, but the epsilon values were zero. Furthermore, time
was recorded for transfering the constant and without transfering the
constant and one can see that transferring data is clearly the bottle neck. 
 
\begin{equation}
    s = \frac{t_{serial}}{t_{parallel}}\label{eq1}
\end{equation}

\begin{table}[H]
\centering
\begin{tabular}{@{}|l|c|c|}
\hline
Number of threads and Elements& Speed-Up with constant & Speed-Up without \\ \hline
4096 $10^5$  & 1.278  & 1.545 \\ \hline 
4096 $10^6$  & 2.370  & 2.708 \\ \hline 
4096 $10^7$  & 2.473  & 2.503 \\ \hline 
1024 $10^5$  & 0.698  & 0.758 \\ \hline
1024 $10^6$  & 0.747  & 0.780 \\ \hline
1024 $10^7$  & 0.634  & 0.639 \\ \hline
\end{tabular}
\caption{Speed-Up calculated on Xunil-05}
\end{table}

\end{document}
